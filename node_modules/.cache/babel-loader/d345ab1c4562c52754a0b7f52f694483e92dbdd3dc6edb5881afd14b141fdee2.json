{"ast":null,"code":"/**\r\n * @typedef {import('micromark-util-types').Chunk} Chunk\r\n * @typedef {import('micromark-util-types').Event} Event\r\n * @typedef {import('micromark-util-types').Token} Token\r\n */\n\nimport { splice } from 'micromark-util-chunked';\n/**\r\n * Tokenize subcontent.\r\n *\r\n * @param {Array<Event>} events\r\n *   List of events.\r\n * @returns {boolean}\r\n *   Whether subtokens were found.\r\n */\nexport function subtokenize(events) {\n  /** @type {Record<string, number>} */\n  var jumps = {};\n  var index = -1;\n  /** @type {Event} */\n  var event;\n  /** @type {number | undefined} */\n  var lineIndex;\n  /** @type {number} */\n  var otherIndex;\n  /** @type {Event} */\n  var otherEvent;\n  /** @type {Array<Event>} */\n  var parameters;\n  /** @type {Array<Event>} */\n  var subevents;\n  /** @type {boolean | undefined} */\n  var more;\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index];\n    }\n    event = events[index];\n\n    // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n    if (index && event[1].type === 'chunkFlow' && events[index - 1][1].type === 'listItemPrefix') {\n      subevents = event[1]._tokenizer.events;\n      otherIndex = 0;\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === 'lineEndingBlank') {\n        otherIndex += 2;\n      }\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === 'content') {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === 'content') {\n            break;\n          }\n          if (subevents[otherIndex][1].type === 'chunkText') {\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true;\n            otherIndex++;\n          }\n        }\n      }\n    }\n\n    // Enter.\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        Object.assign(jumps, subcontent(events, index));\n        index = jumps[index];\n        more = true;\n      }\n    }\n    // Exit.\n    else if (event[1]._container) {\n      otherIndex = index;\n      lineIndex = undefined;\n      while (otherIndex--) {\n        otherEvent = events[otherIndex];\n        if (otherEvent[1].type === 'lineEnding' || otherEvent[1].type === 'lineEndingBlank') {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events[lineIndex][1].type = 'lineEndingBlank';\n            }\n            otherEvent[1].type = 'lineEnding';\n            lineIndex = otherIndex;\n          }\n        } else {\n          break;\n        }\n      }\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = Object.assign({}, events[lineIndex][1].start);\n\n        // Switch container exit w/ line endings.\n        parameters = events.slice(lineIndex, index);\n        parameters.unshift(event);\n        splice(events, lineIndex, index - lineIndex + 1, parameters);\n      }\n    }\n  }\n  return !more;\n}\n\n/**\r\n * Tokenize embedded tokens.\r\n *\r\n * @param {Array<Event>} events\r\n * @param {number} eventIndex\r\n * @returns {Record<string, number>}\r\n */\nfunction subcontent(events, eventIndex) {\n  var token = events[eventIndex][1];\n  var context = events[eventIndex][2];\n  var startPosition = eventIndex - 1;\n  /** @type {Array<number>} */\n  var startPositions = [];\n  var tokenizer = token._tokenizer || context.parser[token.contentType](token.start);\n  var childEvents = tokenizer.events;\n  /** @type {Array<[number, number]>} */\n  var jumps = [];\n  /** @type {Record<string, number>} */\n  var gaps = {};\n  /** @type {Array<Chunk>} */\n  var stream;\n  /** @type {Token | undefined} */\n  var previous;\n  var index = -1;\n  /** @type {Token | undefined} */\n  var current = token;\n  var adjust = 0;\n  var start = 0;\n  var breaks = [start];\n\n  // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n  while (current) {\n    // Find the position of the event for this token.\n    while (events[++startPosition][1] !== current) {\n      // Empty.\n    }\n    startPositions.push(startPosition);\n    if (!current._tokenizer) {\n      stream = context.sliceStream(current);\n      if (!current.next) {\n        stream.push(null);\n      }\n      if (previous) {\n        tokenizer.defineSkip(current.start);\n      }\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true;\n      }\n      tokenizer.write(stream);\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined;\n      }\n    }\n\n    // Unravel the next token.\n    previous = current;\n    current = current.next;\n  }\n\n  // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n  current = token;\n  while (++index < childEvents.length) {\n    if (\n    // Find a void token that includes a break.\n    childEvents[index][0] === 'exit' && childEvents[index - 1][0] === 'enter' && childEvents[index][1].type === childEvents[index - 1][1].type && childEvents[index][1].start.line !== childEvents[index][1].end.line) {\n      start = index + 1;\n      breaks.push(start);\n      // Help GC.\n      current._tokenizer = undefined;\n      current.previous = undefined;\n      current = current.next;\n    }\n  }\n\n  // Help GC.\n  tokenizer.events = [];\n\n  // If there’s one more token (which is the cases for lines that end in an\n  // EOF), that’s perfect: the last point we found starts it.\n  // If there isn’t then make sure any remaining content is added to it.\n  if (current) {\n    // Help GC.\n    current._tokenizer = undefined;\n    current.previous = undefined;\n  } else {\n    breaks.pop();\n  }\n\n  // Now splice the events from the subtokenizer into the current events,\n  // moving back to front so that splice indices aren’t affected.\n  index = breaks.length;\n  while (index--) {\n    var slice = childEvents.slice(breaks[index], breaks[index + 1]);\n    var _start = startPositions.pop();\n    jumps.unshift([_start, _start + slice.length - 1]);\n    splice(events, _start, 2, slice);\n  }\n  index = -1;\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1];\n    adjust += jumps[index][1] - jumps[index][0] - 1;\n  }\n  return gaps;\n}","map":{"version":3,"names":["splice","subtokenize","events","jumps","index","event","lineIndex","otherIndex","otherEvent","parameters","subevents","more","length","type","_tokenizer","_isInFirstContentOfListItem","contentType","Object","assign","subcontent","_container","undefined","end","start","slice","unshift","eventIndex","token","context","startPosition","startPositions","tokenizer","parser","childEvents","gaps","stream","previous","current","adjust","breaks","push","sliceStream","next","defineSkip","_gfmTasklistFirstContentOfListItem","write","line","pop"],"sources":["C:/mayankcse.github.io/node_modules/micromark-util-subtokenize/index.js"],"sourcesContent":["/**\r\n * @typedef {import('micromark-util-types').Chunk} Chunk\r\n * @typedef {import('micromark-util-types').Event} Event\r\n * @typedef {import('micromark-util-types').Token} Token\r\n */\r\n\r\nimport {splice} from 'micromark-util-chunked'\r\n/**\r\n * Tokenize subcontent.\r\n *\r\n * @param {Array<Event>} events\r\n *   List of events.\r\n * @returns {boolean}\r\n *   Whether subtokens were found.\r\n */\r\nexport function subtokenize(events) {\r\n  /** @type {Record<string, number>} */\r\n  const jumps = {}\r\n  let index = -1\r\n  /** @type {Event} */\r\n  let event\r\n  /** @type {number | undefined} */\r\n  let lineIndex\r\n  /** @type {number} */\r\n  let otherIndex\r\n  /** @type {Event} */\r\n  let otherEvent\r\n  /** @type {Array<Event>} */\r\n  let parameters\r\n  /** @type {Array<Event>} */\r\n  let subevents\r\n  /** @type {boolean | undefined} */\r\n  let more\r\n  while (++index < events.length) {\r\n    while (index in jumps) {\r\n      index = jumps[index]\r\n    }\r\n    event = events[index]\r\n\r\n    // Add a hook for the GFM tasklist extension, which needs to know if text\r\n    // is in the first content of a list item.\r\n    if (\r\n      index &&\r\n      event[1].type === 'chunkFlow' &&\r\n      events[index - 1][1].type === 'listItemPrefix'\r\n    ) {\r\n      subevents = event[1]._tokenizer.events\r\n      otherIndex = 0\r\n      if (\r\n        otherIndex < subevents.length &&\r\n        subevents[otherIndex][1].type === 'lineEndingBlank'\r\n      ) {\r\n        otherIndex += 2\r\n      }\r\n      if (\r\n        otherIndex < subevents.length &&\r\n        subevents[otherIndex][1].type === 'content'\r\n      ) {\r\n        while (++otherIndex < subevents.length) {\r\n          if (subevents[otherIndex][1].type === 'content') {\r\n            break\r\n          }\r\n          if (subevents[otherIndex][1].type === 'chunkText') {\r\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true\r\n            otherIndex++\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    // Enter.\r\n    if (event[0] === 'enter') {\r\n      if (event[1].contentType) {\r\n        Object.assign(jumps, subcontent(events, index))\r\n        index = jumps[index]\r\n        more = true\r\n      }\r\n    }\r\n    // Exit.\r\n    else if (event[1]._container) {\r\n      otherIndex = index\r\n      lineIndex = undefined\r\n      while (otherIndex--) {\r\n        otherEvent = events[otherIndex]\r\n        if (\r\n          otherEvent[1].type === 'lineEnding' ||\r\n          otherEvent[1].type === 'lineEndingBlank'\r\n        ) {\r\n          if (otherEvent[0] === 'enter') {\r\n            if (lineIndex) {\r\n              events[lineIndex][1].type = 'lineEndingBlank'\r\n            }\r\n            otherEvent[1].type = 'lineEnding'\r\n            lineIndex = otherIndex\r\n          }\r\n        } else {\r\n          break\r\n        }\r\n      }\r\n      if (lineIndex) {\r\n        // Fix position.\r\n        event[1].end = Object.assign({}, events[lineIndex][1].start)\r\n\r\n        // Switch container exit w/ line endings.\r\n        parameters = events.slice(lineIndex, index)\r\n        parameters.unshift(event)\r\n        splice(events, lineIndex, index - lineIndex + 1, parameters)\r\n      }\r\n    }\r\n  }\r\n  return !more\r\n}\r\n\r\n/**\r\n * Tokenize embedded tokens.\r\n *\r\n * @param {Array<Event>} events\r\n * @param {number} eventIndex\r\n * @returns {Record<string, number>}\r\n */\r\nfunction subcontent(events, eventIndex) {\r\n  const token = events[eventIndex][1]\r\n  const context = events[eventIndex][2]\r\n  let startPosition = eventIndex - 1\r\n  /** @type {Array<number>} */\r\n  const startPositions = []\r\n  const tokenizer =\r\n    token._tokenizer || context.parser[token.contentType](token.start)\r\n  const childEvents = tokenizer.events\r\n  /** @type {Array<[number, number]>} */\r\n  const jumps = []\r\n  /** @type {Record<string, number>} */\r\n  const gaps = {}\r\n  /** @type {Array<Chunk>} */\r\n  let stream\r\n  /** @type {Token | undefined} */\r\n  let previous\r\n  let index = -1\r\n  /** @type {Token | undefined} */\r\n  let current = token\r\n  let adjust = 0\r\n  let start = 0\r\n  const breaks = [start]\r\n\r\n  // Loop forward through the linked tokens to pass them in order to the\r\n  // subtokenizer.\r\n  while (current) {\r\n    // Find the position of the event for this token.\r\n    while (events[++startPosition][1] !== current) {\r\n      // Empty.\r\n    }\r\n    startPositions.push(startPosition)\r\n    if (!current._tokenizer) {\r\n      stream = context.sliceStream(current)\r\n      if (!current.next) {\r\n        stream.push(null)\r\n      }\r\n      if (previous) {\r\n        tokenizer.defineSkip(current.start)\r\n      }\r\n      if (current._isInFirstContentOfListItem) {\r\n        tokenizer._gfmTasklistFirstContentOfListItem = true\r\n      }\r\n      tokenizer.write(stream)\r\n      if (current._isInFirstContentOfListItem) {\r\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined\r\n      }\r\n    }\r\n\r\n    // Unravel the next token.\r\n    previous = current\r\n    current = current.next\r\n  }\r\n\r\n  // Now, loop back through all events (and linked tokens), to figure out which\r\n  // parts belong where.\r\n  current = token\r\n  while (++index < childEvents.length) {\r\n    if (\r\n      // Find a void token that includes a break.\r\n      childEvents[index][0] === 'exit' &&\r\n      childEvents[index - 1][0] === 'enter' &&\r\n      childEvents[index][1].type === childEvents[index - 1][1].type &&\r\n      childEvents[index][1].start.line !== childEvents[index][1].end.line\r\n    ) {\r\n      start = index + 1\r\n      breaks.push(start)\r\n      // Help GC.\r\n      current._tokenizer = undefined\r\n      current.previous = undefined\r\n      current = current.next\r\n    }\r\n  }\r\n\r\n  // Help GC.\r\n  tokenizer.events = []\r\n\r\n  // If there’s one more token (which is the cases for lines that end in an\r\n  // EOF), that’s perfect: the last point we found starts it.\r\n  // If there isn’t then make sure any remaining content is added to it.\r\n  if (current) {\r\n    // Help GC.\r\n    current._tokenizer = undefined\r\n    current.previous = undefined\r\n  } else {\r\n    breaks.pop()\r\n  }\r\n\r\n  // Now splice the events from the subtokenizer into the current events,\r\n  // moving back to front so that splice indices aren’t affected.\r\n  index = breaks.length\r\n  while (index--) {\r\n    const slice = childEvents.slice(breaks[index], breaks[index + 1])\r\n    const start = startPositions.pop()\r\n    jumps.unshift([start, start + slice.length - 1])\r\n    splice(events, start, 2, slice)\r\n  }\r\n  index = -1\r\n  while (++index < jumps.length) {\r\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1]\r\n    adjust += jumps[index][1] - jumps[index][0] - 1\r\n  }\r\n  return gaps\r\n}\r\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;;AAEA,SAAQA,MAAM,QAAO,wBAAwB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,SAASC,WAAWA,CAACC,MAAM,EAAE;EAClC;EACA,IAAMC,KAAK,GAAG,CAAC,CAAC;EAChB,IAAIC,KAAK,GAAG,CAAC,CAAC;EACd;EACA,IAAIC,KAAK;EACT;EACA,IAAIC,SAAS;EACb;EACA,IAAIC,UAAU;EACd;EACA,IAAIC,UAAU;EACd;EACA,IAAIC,UAAU;EACd;EACA,IAAIC,SAAS;EACb;EACA,IAAIC,IAAI;EACR,OAAO,EAAEP,KAAK,GAAGF,MAAM,CAACU,MAAM,EAAE;IAC9B,OAAOR,KAAK,IAAID,KAAK,EAAE;MACrBC,KAAK,GAAGD,KAAK,CAACC,KAAK,CAAC;IACtB;IACAC,KAAK,GAAGH,MAAM,CAACE,KAAK,CAAC;;IAErB;IACA;IACA,IACEA,KAAK,IACLC,KAAK,CAAC,CAAC,CAAC,CAACQ,IAAI,KAAK,WAAW,IAC7BX,MAAM,CAACE,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAACS,IAAI,KAAK,gBAAgB,EAC9C;MACAH,SAAS,GAAGL,KAAK,CAAC,CAAC,CAAC,CAACS,UAAU,CAACZ,MAAM;MACtCK,UAAU,GAAG,CAAC;MACd,IACEA,UAAU,GAAGG,SAAS,CAACE,MAAM,IAC7BF,SAAS,CAACH,UAAU,CAAC,CAAC,CAAC,CAAC,CAACM,IAAI,KAAK,iBAAiB,EACnD;QACAN,UAAU,IAAI,CAAC;MACjB;MACA,IACEA,UAAU,GAAGG,SAAS,CAACE,MAAM,IAC7BF,SAAS,CAACH,UAAU,CAAC,CAAC,CAAC,CAAC,CAACM,IAAI,KAAK,SAAS,EAC3C;QACA,OAAO,EAAEN,UAAU,GAAGG,SAAS,CAACE,MAAM,EAAE;UACtC,IAAIF,SAAS,CAACH,UAAU,CAAC,CAAC,CAAC,CAAC,CAACM,IAAI,KAAK,SAAS,EAAE;YAC/C;UACF;UACA,IAAIH,SAAS,CAACH,UAAU,CAAC,CAAC,CAAC,CAAC,CAACM,IAAI,KAAK,WAAW,EAAE;YACjDH,SAAS,CAACH,UAAU,CAAC,CAAC,CAAC,CAAC,CAACQ,2BAA2B,GAAG,IAAI;YAC3DR,UAAU,EAAE;UACd;QACF;MACF;IACF;;IAEA;IACA,IAAIF,KAAK,CAAC,CAAC,CAAC,KAAK,OAAO,EAAE;MACxB,IAAIA,KAAK,CAAC,CAAC,CAAC,CAACW,WAAW,EAAE;QACxBC,MAAM,CAACC,MAAM,CAACf,KAAK,EAAEgB,UAAU,CAACjB,MAAM,EAAEE,KAAK,CAAC,CAAC;QAC/CA,KAAK,GAAGD,KAAK,CAACC,KAAK,CAAC;QACpBO,IAAI,GAAG,IAAI;MACb;IACF;IACA;IAAA,KACK,IAAIN,KAAK,CAAC,CAAC,CAAC,CAACe,UAAU,EAAE;MAC5Bb,UAAU,GAAGH,KAAK;MAClBE,SAAS,GAAGe,SAAS;MACrB,OAAOd,UAAU,EAAE,EAAE;QACnBC,UAAU,GAAGN,MAAM,CAACK,UAAU,CAAC;QAC/B,IACEC,UAAU,CAAC,CAAC,CAAC,CAACK,IAAI,KAAK,YAAY,IACnCL,UAAU,CAAC,CAAC,CAAC,CAACK,IAAI,KAAK,iBAAiB,EACxC;UACA,IAAIL,UAAU,CAAC,CAAC,CAAC,KAAK,OAAO,EAAE;YAC7B,IAAIF,SAAS,EAAE;cACbJ,MAAM,CAACI,SAAS,CAAC,CAAC,CAAC,CAAC,CAACO,IAAI,GAAG,iBAAiB;YAC/C;YACAL,UAAU,CAAC,CAAC,CAAC,CAACK,IAAI,GAAG,YAAY;YACjCP,SAAS,GAAGC,UAAU;UACxB;QACF,CAAC,MAAM;UACL;QACF;MACF;MACA,IAAID,SAAS,EAAE;QACb;QACAD,KAAK,CAAC,CAAC,CAAC,CAACiB,GAAG,GAAGL,MAAM,CAACC,MAAM,CAAC,CAAC,CAAC,EAAEhB,MAAM,CAACI,SAAS,CAAC,CAAC,CAAC,CAAC,CAACiB,KAAK,CAAC;;QAE5D;QACAd,UAAU,GAAGP,MAAM,CAACsB,KAAK,CAAClB,SAAS,EAAEF,KAAK,CAAC;QAC3CK,UAAU,CAACgB,OAAO,CAACpB,KAAK,CAAC;QACzBL,MAAM,CAACE,MAAM,EAAEI,SAAS,EAAEF,KAAK,GAAGE,SAAS,GAAG,CAAC,EAAEG,UAAU,CAAC;MAC9D;IACF;EACF;EACA,OAAO,CAACE,IAAI;AACd;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASQ,UAAUA,CAACjB,MAAM,EAAEwB,UAAU,EAAE;EACtC,IAAMC,KAAK,GAAGzB,MAAM,CAACwB,UAAU,CAAC,CAAC,CAAC,CAAC;EACnC,IAAME,OAAO,GAAG1B,MAAM,CAACwB,UAAU,CAAC,CAAC,CAAC,CAAC;EACrC,IAAIG,aAAa,GAAGH,UAAU,GAAG,CAAC;EAClC;EACA,IAAMI,cAAc,GAAG,EAAE;EACzB,IAAMC,SAAS,GACbJ,KAAK,CAACb,UAAU,IAAIc,OAAO,CAACI,MAAM,CAACL,KAAK,CAACX,WAAW,CAAC,CAACW,KAAK,CAACJ,KAAK,CAAC;EACpE,IAAMU,WAAW,GAAGF,SAAS,CAAC7B,MAAM;EACpC;EACA,IAAMC,KAAK,GAAG,EAAE;EAChB;EACA,IAAM+B,IAAI,GAAG,CAAC,CAAC;EACf;EACA,IAAIC,MAAM;EACV;EACA,IAAIC,QAAQ;EACZ,IAAIhC,KAAK,GAAG,CAAC,CAAC;EACd;EACA,IAAIiC,OAAO,GAAGV,KAAK;EACnB,IAAIW,MAAM,GAAG,CAAC;EACd,IAAIf,KAAK,GAAG,CAAC;EACb,IAAMgB,MAAM,GAAG,CAAChB,KAAK,CAAC;;EAEtB;EACA;EACA,OAAOc,OAAO,EAAE;IACd;IACA,OAAOnC,MAAM,CAAC,EAAE2B,aAAa,CAAC,CAAC,CAAC,CAAC,KAAKQ,OAAO,EAAE;MAC7C;IAAA;IAEFP,cAAc,CAACU,IAAI,CAACX,aAAa,CAAC;IAClC,IAAI,CAACQ,OAAO,CAACvB,UAAU,EAAE;MACvBqB,MAAM,GAAGP,OAAO,CAACa,WAAW,CAACJ,OAAO,CAAC;MACrC,IAAI,CAACA,OAAO,CAACK,IAAI,EAAE;QACjBP,MAAM,CAACK,IAAI,CAAC,IAAI,CAAC;MACnB;MACA,IAAIJ,QAAQ,EAAE;QACZL,SAAS,CAACY,UAAU,CAACN,OAAO,CAACd,KAAK,CAAC;MACrC;MACA,IAAIc,OAAO,CAACtB,2BAA2B,EAAE;QACvCgB,SAAS,CAACa,kCAAkC,GAAG,IAAI;MACrD;MACAb,SAAS,CAACc,KAAK,CAACV,MAAM,CAAC;MACvB,IAAIE,OAAO,CAACtB,2BAA2B,EAAE;QACvCgB,SAAS,CAACa,kCAAkC,GAAGvB,SAAS;MAC1D;IACF;;IAEA;IACAe,QAAQ,GAAGC,OAAO;IAClBA,OAAO,GAAGA,OAAO,CAACK,IAAI;EACxB;;EAEA;EACA;EACAL,OAAO,GAAGV,KAAK;EACf,OAAO,EAAEvB,KAAK,GAAG6B,WAAW,CAACrB,MAAM,EAAE;IACnC;IACE;IACAqB,WAAW,CAAC7B,KAAK,CAAC,CAAC,CAAC,CAAC,KAAK,MAAM,IAChC6B,WAAW,CAAC7B,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,OAAO,IACrC6B,WAAW,CAAC7B,KAAK,CAAC,CAAC,CAAC,CAAC,CAACS,IAAI,KAAKoB,WAAW,CAAC7B,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAACS,IAAI,IAC7DoB,WAAW,CAAC7B,KAAK,CAAC,CAAC,CAAC,CAAC,CAACmB,KAAK,CAACuB,IAAI,KAAKb,WAAW,CAAC7B,KAAK,CAAC,CAAC,CAAC,CAAC,CAACkB,GAAG,CAACwB,IAAI,EACnE;MACAvB,KAAK,GAAGnB,KAAK,GAAG,CAAC;MACjBmC,MAAM,CAACC,IAAI,CAACjB,KAAK,CAAC;MAClB;MACAc,OAAO,CAACvB,UAAU,GAAGO,SAAS;MAC9BgB,OAAO,CAACD,QAAQ,GAAGf,SAAS;MAC5BgB,OAAO,GAAGA,OAAO,CAACK,IAAI;IACxB;EACF;;EAEA;EACAX,SAAS,CAAC7B,MAAM,GAAG,EAAE;;EAErB;EACA;EACA;EACA,IAAImC,OAAO,EAAE;IACX;IACAA,OAAO,CAACvB,UAAU,GAAGO,SAAS;IAC9BgB,OAAO,CAACD,QAAQ,GAAGf,SAAS;EAC9B,CAAC,MAAM;IACLkB,MAAM,CAACQ,GAAG,CAAC,CAAC;EACd;;EAEA;EACA;EACA3C,KAAK,GAAGmC,MAAM,CAAC3B,MAAM;EACrB,OAAOR,KAAK,EAAE,EAAE;IACd,IAAMoB,KAAK,GAAGS,WAAW,CAACT,KAAK,CAACe,MAAM,CAACnC,KAAK,CAAC,EAAEmC,MAAM,CAACnC,KAAK,GAAG,CAAC,CAAC,CAAC;IACjE,IAAMmB,MAAK,GAAGO,cAAc,CAACiB,GAAG,CAAC,CAAC;IAClC5C,KAAK,CAACsB,OAAO,CAAC,CAACF,MAAK,EAAEA,MAAK,GAAGC,KAAK,CAACZ,MAAM,GAAG,CAAC,CAAC,CAAC;IAChDZ,MAAM,CAACE,MAAM,EAAEqB,MAAK,EAAE,CAAC,EAAEC,KAAK,CAAC;EACjC;EACApB,KAAK,GAAG,CAAC,CAAC;EACV,OAAO,EAAEA,KAAK,GAAGD,KAAK,CAACS,MAAM,EAAE;IAC7BsB,IAAI,CAACI,MAAM,GAAGnC,KAAK,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,GAAGkC,MAAM,GAAGnC,KAAK,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC;IACzDkC,MAAM,IAAInC,KAAK,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC,GAAGD,KAAK,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;EACjD;EACA,OAAO8B,IAAI;AACb"},"metadata":{},"sourceType":"module","externalDependencies":[]}